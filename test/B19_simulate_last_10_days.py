import pandas as pd
import numpy as np
from collections import defaultdict
import os
from typing import Dict, List, Tuple

# --- é€™æ˜¯æ¨¡æ“¬éŽåŽ»äº¤æ˜“æ—¥é æ¸¬çµæžœçš„è…³æœ¬ ---

# è¨­å®šæ¨¡æ“¬åƒæ•¸
simulation_days = 30

# 1. å»ºç«‹èˆ‡æ­£å¼è…³æœ¬(predict.py)ä¸­å®Œå…¨ç›¸åŒçš„è²è‘‰æ–¯åˆ†é¡žå™¨
class NaiveBayesClassifier:
    """ç°¡å–®çš„é¡žåˆ¥åž‹æ¨¸ç´ è²è‘‰æ–¯åˆ†é¡žå™¨ï¼Œæ”¯æ´æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ã€‚"""

    def __init__(self, laplace_smoothing: float = 1.0) -> None:
        if laplace_smoothing <= 0:
            raise ValueError('laplace_smoothing å¿…é ˆç‚ºæ­£æ•¸')
        self.laplace_smoothing = float(laplace_smoothing)
        self.priors = {}
        self.likelihoods = defaultdict(lambda: defaultdict(dict))
        self.features = []
        self.classes_ = []

    def fit(self, X, y):
        if len(X) != len(y):
            raise ValueError('ç‰¹å¾µèˆ‡æ¨™ç±¤é•·åº¦ä¸ä¸€è‡´')

        y = pd.Series(y)
        self.features = list(X.columns)
        # ç¢ºä¿é¡žåˆ¥åŒ…å« -1, 0, 1ï¼Œå³ä½¿æ•¸æ“šä¸­å¯èƒ½æš«æ™‚æ²’æœ‰
        # é€™å°æ–¼ä¸‰æ…‹äº¤æ˜“è¨Šè™Ÿï¼ˆè²·å…¥ã€æŒæœ‰ã€è³£å‡ºï¼‰å¾ˆé‡è¦
        unique_classes = sorted(y.unique().tolist())
        # å°‡é¡žåˆ¥çµ±ä¸€ç‚ºå­—ä¸²åž‹æ…‹
        if isinstance(unique_classes[0], str):
            self.classes_ = sorted(list(set(unique_classes + ['è²·å…¥', 'æŒæœ‰', 'è³£å‡º'])))
        else:
            self.classes_ = sorted(list(set(unique_classes)))
        n_samples = len(y)

        if not self.classes_:
            raise ValueError('è¨“ç·´è³‡æ–™ä¸­æ²’æœ‰ä»»ä½•é¡žåˆ¥æ¨™ç±¤')

        for action in self.classes_:
            action_count = int((y == action).sum())
            self.priors[action] = (action_count + self.laplace_smoothing) / (
                n_samples + self.laplace_smoothing * len(self.classes_)
            )

        for feature in self.features:
            feature_series = X[feature]
            unique_values = pd.Series(feature_series.unique()).dropna().tolist()
            if not unique_values:
                unique_values = [0.0]
            num_unique = len(unique_values)

            for action in self.classes_:
                action_mask = y == action
                feature_values_in_action = feature_series[action_mask]
                value_counts = feature_values_in_action.value_counts()
                total_in_action = len(feature_values_in_action)

                denominator = total_in_action + num_unique * self.laplace_smoothing
                if denominator == 0:
                    denominator = num_unique * self.laplace_smoothing

                for value in unique_values:
                    value_key = value
                    count = value_counts.get(value, 0)
                    probability = (count + self.laplace_smoothing) / denominator
                    self.likelihoods[feature][action][value_key] = probability

                # è‹¥é‡åˆ°æœªè¦‹å€¼ï¼Œçµ¦äºˆæ¥µå°å¹³æ»‘æ©ŸçŽ‡å‚™ç”¨
                self.likelihoods[feature][action]['__unknown__'] = self.laplace_smoothing / (
                    denominator if denominator > 0 else self.laplace_smoothing * num_unique
                )

        return self

    def _compute_log_posteriors(self, row):
        posteriors = {}
        for action in self.classes_:
            log_posterior = float(np.log(self.priors.get(action, 1e-12)))
            for feature in self.features:
                value_key = row.get(feature)
                feature_likelihoods = self.likelihoods.get(feature, {}).get(action, {})
                probability = feature_likelihoods.get(value_key)
                if probability is None or probability <= 0:
                    probability = feature_likelihoods.get('__unknown__', 1e-12)
                log_posterior += float(np.log(probability))
            posteriors[action] = log_posterior
        return posteriors

    def predict_log_proba(self, X):
        log_probas = []
        for _, row in X.iterrows():
            posteriors = self._compute_log_posteriors(row)
            log_probas.append([posteriors[action] for action in self.classes_])
        return np.array(log_probas)

    def predict_proba(self, X):
        log_probas = self.predict_log_proba(X)
        # ä½¿ç”¨ log-sum-exp è½‰æ›ç‚ºå¯¦éš›æ©ŸçŽ‡
        max_log = log_probas.max(axis=1, keepdims=True)
        stabilized = np.exp(log_probas - max_log)
        sums = stabilized.sum(axis=1, keepdims=True)
        with np.errstate(divide='ignore', invalid='ignore'):
            probas = np.divide(stabilized, sums, where=sums > 0)
        return probas

    def predict(self, X):
        if isinstance(X, pd.Series):
            X = pd.DataFrame([X])
        probas = self.predict_proba(X)
        class_indices = np.argmax(probas, axis=1)
        return np.array([self.classes_[idx] for idx in class_indices])

# å®šç¾©èˆ‡æ­£å¼æ¨¡åž‹ç›¸åŒçš„äº¤æ˜“è¨Šè™Ÿå‡½æ•¸
FUTURE_DAYS = 5
PCT_CHANGE_THRESHOLD = 0.03

def define_signal(price_change):
    """
    æ ¹æ“šåƒ¹æ ¼è®ŠåŒ–å®šç¾©äº¤æ˜“è¨Šè™Ÿ
    
    Args:
        price_change: åƒ¹æ ¼è®ŠåŒ–ç™¾åˆ†æ¯”
        
    Returns:
        str: äº¤æ˜“è¨Šè™Ÿ - 'è²·å…¥', 'è³£å‡º' æˆ– 'æŒæœ‰'
    """
    if price_change > PCT_CHANGE_THRESHOLD:
        return 'è²·å…¥'
    elif price_change < -PCT_CHANGE_THRESHOLD:
        return 'è³£å‡º'
    else:
        return 'æŒæœ‰'

def get_prediction_for_data(dataframe):
    """
    æŽ¥æ”¶ä¸€å€‹ DataFrameï¼Œè¨“ç·´æ¨¡åž‹ä¸¦å›žå‚³å°å…¶æœ€å¾Œä¸€ç­†è³‡æ–™çš„é æ¸¬ã€‚
    è¿”å›žé æ¸¬è¨Šè™Ÿã€æ—¥æœŸã€ä¿¡å¿ƒå€¼å’Œæ‰€æœ‰é¡žåˆ¥æ¦‚çŽ‡
    """
    # æº–å‚™è¨“ç·´è³‡æ–™
    feature_columns = [col for col in dataframe.columns if col.endswith('_bin')]
    df_train = dataframe[['Date'] + feature_columns + ['Close']].copy()

    df_train['Future_Close'] = df_train['Close'].shift(-FUTURE_DAYS)
    df_train['Price_Change'] = (df_train['Future_Close'] - df_train['Close']) / df_train['Close']

    df_train.dropna(subset=['Future_Close'], inplace=True)
    df_train['Action'] = df_train['Price_Change'].apply(define_signal)

    # è¨“ç·´æ¨¡åž‹
    X_train_full = df_train[feature_columns]
    y_train_full = df_train['Action']
    
    if len(X_train_full) == 0:
        return "è³‡æ–™ä¸è¶³ç„¡æ³•é æ¸¬", None, None, None

    model = NaiveBayesClassifier()
    model.fit(X_train_full, y_train_full)

    # æº–å‚™é æ¸¬è³‡æ–™ (ä½¿ç”¨å‚³å…¥ dataframe çš„æœ€å¾Œä¸€ç­†)
    latest_data = dataframe.iloc[-1]
    X_predict = latest_data[feature_columns]
    
    # å‰µå»ºé æ¸¬ç”¨çš„ DataFrame
    X_predict_df = pd.DataFrame([X_predict])
    
    # é€²è¡Œé æ¸¬
    predicted_signal = model.predict(X_predict_df)[0]
    
    # è¨ˆç®—ä¿¡å¿ƒå€¼å’Œæ¦‚çŽ‡åˆ†å¸ƒ
    probas = model.predict_proba(X_predict_df)[0]
    confidence = float(np.max(probas))
    
    # å‰µå»ºé¡žåˆ¥æ¦‚çŽ‡å­—å…¸
    class_probs = {cls: float(prob) for cls, prob in zip(model.classes_, probas)}
    
    return predicted_signal, latest_data['Date'], confidence, class_probs

# 2. è¼‰å…¥å®Œæ•´çš„æ­·å²è³‡æ–™
try:
    # è¼‰å…¥ç‰¹å¾µè³‡æ–™
    full_df = pd.read_csv('data/final_data.csv', parse_dates=['Date'])
    if len(full_df) < simulation_days:
        print(f"è­¦å‘Šï¼šå¯ç”¨æ•¸æ“šåªæœ‰ {len(full_df)} ç­†ï¼Œå°‘æ–¼è«‹æ±‚çš„ {simulation_days} å¤©ã€‚")
        print(f"å°‡æ¨¡æ“¬å¤©æ•¸èª¿æ•´ç‚º {len(full_df)-1} å¤©ã€‚")
        simulation_days = len(full_df) - 1
    
    # è¼‰å…¥é–‹ç›¤åƒ¹æ ¼è³‡æ–™
    price_df = pd.read_csv('data/data.csv', parse_dates=['Date'])
    print(f"æˆåŠŸè¼‰å…¥åŽŸå§‹åƒ¹æ ¼è³‡æ–™ï¼Œå…± {len(price_df)} ç­†è¨˜éŒ„")
    
    # ç¢ºä¿å…©å€‹æ•¸æ“šæ¡†çš„æ—¥æœŸæ ¼å¼ä¸€è‡´
    print(f"final_data.csv æ—¥æœŸç¯„ä¾‹: {full_df['Date'].iloc[0]}")
    print(f"data.csv æ—¥æœŸç¯„ä¾‹: {price_df['Date'].iloc[0]}")
    
except FileNotFoundError as e:
    print(f"éŒ¯èª¤ï¼šæª”æ¡ˆæ‰¾ä¸åˆ°ã€‚{e}")
    exit()
except Exception as e:
    print(f"è¼‰å…¥æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
    exit()

# 3. è¿´åœˆæ¨¡æ“¬éŽåŽ»äº¤æ˜“æ—¥çš„é æ¸¬
print(f"--- é–‹å§‹æ¨¡æ“¬éŽåŽ» {simulation_days} å¤©çš„æ¯æ—¥é æ¸¬ ---")
print(f"ä½¿ç”¨äº¤æ˜“è¨Šè™Ÿç­–ç•¥: æœªä¾†{FUTURE_DAYS}å¤©åƒ¹æ ¼è®ŠåŒ–é–¾å€¼ {PCT_CHANGE_THRESHOLD*100:.1f}%\n")

# æª¢æŸ¥æ•¸æ“šæ¬„ä½
available_columns = full_df.columns.tolist()
print(f"å¯ç”¨æ•¸æ“šæ¬„ä½: {', '.join(available_columns)}")

# æº–å‚™çµæžœè¼¸å‡ºæ–‡ä»¶
output_file_path = 'data/prediction_history_30days.txt'
output_lines = []
output_lines.append(f"--- æ¨¡æ“¬éŽåŽ» {simulation_days} å¤©çš„æ¯æ—¥é æ¸¬ ---")
output_lines.append(f"ä½¿ç”¨äº¤æ˜“è¨Šè™Ÿç­–ç•¥: æœªä¾†{FUTURE_DAYS}å¤©åƒ¹æ ¼è®ŠåŒ–é–¾å€¼ {PCT_CHANGE_THRESHOLD*100:.1f}%\n")

for i in range(simulation_days, 0, -1):
    # æ¯æ¬¡éƒ½å¾žå®Œæ•´è³‡æ–™ä¸­åˆ‡å‰²ï¼Œæ¨¡æ“¬ç•¶æ™‚çš„è³‡æ–™ç‹€æ…‹
    # ä¾‹å¦‚ i=30ï¼Œä»£è¡¨å–åˆ°å€’æ•¸ç¬¬30ç­†è³‡æ–™ç‚ºæ­¢ï¼Œä¾†é æ¸¬å€’æ•¸ç¬¬29å¤©çš„è¨Šè™Ÿ
    end_index = len(full_df) - i
    if end_index < 1:
        continue
        
    temp_df = full_df.iloc[:end_index]
    
    # åŸ·è¡Œé æ¸¬
    signal, last_date, confidence, class_probs = get_prediction_for_data(temp_df)
    
    # å–å¾—åƒ¹æ ¼è³‡è¨Š
    last_close = temp_df.iloc[-1]['Close']
    predict_day_data = full_df.iloc[end_index]
    predict_for_date = predict_day_data['Date']
    
    # å°‹æ‰¾å°æ‡‰æ—¥æœŸçš„é–‹ç›¤åƒ¹æ ¼
    matching_price = price_df[price_df['Date'] == predict_for_date]
    if not matching_price.empty and 'Open' in matching_price.columns:
        predict_next_open = matching_price.iloc[0]['Open']
        print(f"æ‰¾åˆ° {predict_for_date} çš„é–‹ç›¤åƒ¹: {predict_next_open}")
        predict_next_close = predict_next_open  # å°‡é–‹ç›¤åƒ¹ç”¨æ–¼é æ¸¬
    else:
        predict_next_close = predict_day_data['Close']  # å¦‚æžœæ‰¾ä¸åˆ°é–‹ç›¤åƒ¹ï¼Œä½¿ç”¨æ”¶ç›¤åƒ¹æ›¿ä»£

    # ç¢ºå®šè¡¨æƒ…ç¬¦è™Ÿ
    if signal == 'è²·å…¥':
        signal_emoji = 'ðŸŸ¢'
    elif signal == 'è³£å‡º':
        signal_emoji = 'ðŸ”´'
    else:  # signal == 'æŒæœ‰'
        signal_emoji = 'âšª'

    # è¨ˆç®—å¯¦éš›åƒ¹æ ¼è®ŠåŒ–
    if end_index + FUTURE_DAYS < len(full_df):
        future_data = full_df.iloc[end_index + FUTURE_DAYS]
        future_date = future_data['Date']
        
        # å°‹æ‰¾æœªä¾†æ—¥æœŸçš„é–‹ç›¤åƒ¹æ ¼
        future_price_data = price_df[price_df['Date'] == future_date]
        if not future_price_data.empty and 'Open' in future_price_data.columns:
            future_open = future_price_data.iloc[0]['Open']
            # print(f"æ‰¾åˆ° {future_date} çš„é–‹ç›¤åƒ¹: {future_open}")
            actual_change = (future_open - predict_next_close) / predict_next_close
        else:
            future_close = future_data['Close']  # å¦‚æžœæ‰¾ä¸åˆ°é–‹ç›¤åƒ¹ï¼Œä½¿ç”¨æ”¶ç›¤åƒ¹
            actual_change = (future_close - predict_next_close) / predict_next_close
            
        actual_pct = actual_change * 100
        actual_result = f"å¯¦éš›è‡³ {future_date} çš„è®ŠåŒ–: {actual_pct:.2f}%"
    else:
        actual_result = "å°šç„¡è¶³å¤ æœªä¾†è³‡æ–™è¨ˆç®—å¯¦éš›è®ŠåŒ–"

    # æ‰“å°é æ¸¬çµæžœ
    result_line = f"{signal_emoji} åŸºæ–¼ {last_date} (æ”¶ç›¤åƒ¹: {last_close:.2f})ï¼Œé æ¸¬ {predict_for_date} (é–‹ç›¤åƒ¹: {predict_next_close:.2f}) çš„è¨Šè™Ÿç‚ºï¼šã€ {signal} ã€‘"
    confidence_line = f"   ä¿¡å¿ƒå€¼: {confidence:.2%}"
    
    # æ¦‚çŽ‡åˆ†å¸ƒ
    probs_line = "   æ¦‚çŽ‡åˆ†å¸ƒ: "
    for cls, prob in sorted(class_probs.items(), key=lambda x: x[1], reverse=True):
        probs_line += f"{cls}: {prob:.2%} "
    
    # å¯¦éš›çµæžœ
    actual_line = f"   {actual_result}"
    
    # æ‰“å°åˆ°æŽ§åˆ¶å°
    print(result_line)
    print(confidence_line)
    print(probs_line)
    print(actual_line)
    print()
    
    # æ·»åŠ åˆ°è¼¸å‡ºåˆ—è¡¨
    output_lines.append(result_line)
    output_lines.append(confidence_line)
    output_lines.append(probs_line)
    output_lines.append(actual_line)
    output_lines.append("")

# å°‡çµæžœå¯«å…¥æª”æ¡ˆ
output_lines.append("\n--- æ¨¡æ“¬çµæŸ ---")
with open(output_file_path, 'w', encoding='utf-8') as f:
    f.write('\n'.join(output_lines))

print("\n--- æ¨¡æ“¬çµæŸ ---")
print(f"çµæžœå·²å„²å­˜è‡³: {output_file_path}")
