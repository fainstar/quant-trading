from __future__ import annotations

import argparse
import io
import os
import sys
from dataclasses import dataclass
from datetime import datetime, timedelta
from json.decoder import JSONDecodeError
from typing import Callable, Iterable, List, Optional, Tuple

import pandas as pd
import requests
import yfinance as yf


if sys.platform == "win32":
    import io as _io  # type: ignore

    sys.stdout = _io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")  # type: ignore[attr-defined]
    sys.stderr = _io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")  # type: ignore[attr-defined]


_YF_SESSION: Optional[requests.Session] = None
_YF_CRUMB: Optional[str] = None


@dataclass
class FetchAttempt:
    label: str
    loader: Callable[[], pd.DataFrame]


def get_yf_session() -> requests.Session:
    global _YF_SESSION
    if _YF_SESSION is not None:
        return _YF_SESSION

    session = requests.Session()
    session.headers.update(
        {
            "User-Agent": (
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                "AppleWebKit/537.36 (KHTML, like Gecko) "
                "Chrome/128.0.0.0 Safari/537.36"
            ),
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "en-US,en;q=0.9",
            "Cache-Control": "no-cache",
            "Pragma": "no-cache",
            "Connection": "keep-alive",
        }
    )

    _YF_SESSION = session
    return session


def get_yahoo_crumb(session: requests.Session) -> str:
    global _YF_CRUMB
    if _YF_CRUMB:
        return _YF_CRUMB

    resp = session.get("https://query1.finance.yahoo.com/v1/test/getcrumb", timeout=15)
    resp.raise_for_status()
    crumb = resp.text.strip()
    if not crumb:
        raise ValueError("Yahoo Finance crumb ç‚ºç©º")
    _YF_CRUMB = crumb
    return crumb


def warm_up_session(session: requests.Session, ticker_symbol: str) -> None:
    warm_up_urls = [
        f"https://finance.yahoo.com/quote/{ticker_symbol}",
        f"https://query1.finance.yahoo.com/v7/finance/quote?symbols={ticker_symbol}",
    ]

    for url in warm_up_urls:
        try:
            session.get(url, timeout=10)
        except Exception:
            continue

    try:
        get_yahoo_crumb(session)
    except Exception:
        pass


def _normalize_history_df(raw_df: pd.DataFrame, ticker_symbol: str) -> pd.DataFrame:
    if raw_df is None or raw_df.empty:
        raise ValueError("yfinance å›å‚³äº†ç©ºçš„è³‡æ–™é›†")

    df = raw_df.copy()

    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [col[0] if isinstance(col, tuple) and len(col) > 0 else col for col in df.columns]

    if "Date" not in df.columns:
        df = df.reset_index()
    else:
        df = df.reset_index(drop=True)

    if "Date" not in df.columns:
        if "index" in df.columns:
            df.rename(columns={"index": "Date"}, inplace=True)
        else:
            first_col = df.columns[0]
            df.rename(columns={first_col: "Date"}, inplace=True)

    if "Date" not in df.columns:
        raise ValueError("è³‡æ–™ç¼ºå°‘æ—¥æœŸæ¬„ä½ï¼Œç„¡æ³•å¾ŒçºŒè™•ç†")

    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    df = df.dropna(subset=["Date"])
    df["Date"] = df["Date"].dt.strftime("%Y-%m-%d")

    price_columns = ["Open", "High", "Low", "Close"]
    for col in price_columns:
        if col not in df.columns:
            raise ValueError(f"è³‡æ–™ç¼ºå°‘å¿…è¦æ¬„ä½ {col}")
        df[col] = pd.to_numeric(df[col], errors="coerce").round(6)

    df = df.dropna(subset=price_columns)

    if "Volume" not in df.columns:
        df["Volume"] = 0
    else:
        df["Volume"] = pd.to_numeric(df["Volume"], errors="coerce").fillna(0)

    for col in ["Dividends", "Stock Splits"]:
        if col not in df.columns:
            df[col] = 0

    df = df.sort_values("Date").reset_index(drop=True)

    return df


def _direct_download_loader(ticker_symbol: str, years: int) -> pd.DataFrame:
    session = get_yf_session()
    warm_up_session(session, ticker_symbol)
    try:
        crumb = get_yahoo_crumb(session)
    except Exception:
        crumb = None

    end = datetime.utcnow()
    start = end - timedelta(days=int(years * 366))

    params = {
        "period1": int(start.timestamp()),
        "period2": int(end.timestamp()),
        "interval": "1d",
        "events": "history",
        "includeAdjustedClose": "true",
    }

    if crumb:
        params["crumb"] = crumb

    url = f"https://query1.finance.yahoo.com/v7/finance/download/{ticker_symbol}"
    response = session.get(url, params=params, timeout=30)

    if response.status_code != 200:
        raise ValueError(f"HTTP {response.status_code}: {response.text[:120]}")

    if not response.text or response.text.strip().startswith("<!DOCTYPE"):
        raise ValueError("å›å‚³å…§å®¹é CSV")

    csv_buffer = io.StringIO(response.text)
    df = pd.read_csv(csv_buffer)
    return df


def _chart_api_loader(ticker_symbol: str, years: int) -> pd.DataFrame:
    session = get_yf_session()

    params = {
        "interval": "1d",
        "includePrePost": "false",
        "events": "div,splits",
        "corsDomain": "finance.yahoo.com",
    }

    params["range"] = "max" if years > 10 else f"{max(1, years)}y"

    url = f"https://query2.finance.yahoo.com/v8/finance/chart/{ticker_symbol}"
    response = session.get(url, params=params, timeout=30)
    response.raise_for_status()

    try:
        payload = response.json()
    except JSONDecodeError as exc:
        raise ValueError(f"chart api JSON è§£æå¤±æ•—: {exc}") from exc

    chart = payload.get("chart", {})
    error_info = chart.get("error")
    if error_info:
        raise ValueError(f"chart api error: {error_info}")

    results = chart.get("result")
    if not results:
        raise ValueError("chart api ç„¡è¿”å›çµæœ")

    result = results[0]
    timestamps = result.get("timestamp")
    indicators = result.get("indicators", {})
    quote_list = indicators.get("quote", [{}])
    adjclose_list = indicators.get("adjclose", [{}])

    if not timestamps:
        raise ValueError("chart api ç„¡æ™‚é–“æˆ³")

    quote = quote_list[0] if quote_list else {}
    adjclose = adjclose_list[0] if adjclose_list else {}

    df = pd.DataFrame(
        {
            "Date": pd.to_datetime(timestamps, unit="s"),
            "Open": quote.get("open"),
            "High": quote.get("high"),
            "Low": quote.get("low"),
            "Close": quote.get("close"),
            "Adj Close": adjclose.get("adjclose"),
            "Volume": quote.get("volume"),
        }
    )

    if "Adj Close" in df.columns and df["Adj Close"].notna().any():
        df["Close"] = df["Adj Close"].where(df["Adj Close"].notna(), df["Close"])

    df.drop(columns=[col for col in df.columns if col.lower() == "adj close"], inplace=True, errors="ignore")

    return df


def build_fetch_attempts(
    ticker_symbol: str, years: int, session: requests.Session
) -> Tuple[List[FetchAttempt], Optional[str]]:
    attempts: List[FetchAttempt] = []
    initialization_error: Optional[str] = None

    history_periods = [f"{years}y"]
    if years > 5:
        history_periods.append("5y")
    history_periods.append("max")

    try:
        ticker = yf.Ticker(ticker_symbol, session=session)
    except Exception as exc:
        initialization_error = f"åˆå§‹åŒ– yfinance Ticker å¤±æ•—: {exc}"
    else:
        for period in history_periods:
            attempts.append(
                FetchAttempt(
                    label=f"Ticker.history(period={period})",
                    loader=lambda p=period: ticker.history(
                        period=p,
                        interval="1d",
                        auto_adjust=False,
                        actions=True,
                    ),
                )
            )

    download_periods = [f"{years}y", "max"]
    for period in download_periods:
        attempts.append(
            FetchAttempt(
                label=f"yf.download(period={period})",
                loader=lambda p=period: yf.download(
                    tickers=ticker_symbol,
                    period=p,
                    interval="1d",
                    auto_adjust=False,
                    actions=True,
                    progress=False,
                    threads=False,
                    session=session,
                ),
            )
        )

    attempts.append(
        FetchAttempt(
            label="direct_csv_download",
            loader=lambda: _direct_download_loader(ticker_symbol, years),
        )
    )

    attempts.append(
        FetchAttempt(
            label="chart_api",
            loader=lambda: _chart_api_loader(ticker_symbol, years),
        )
    )

    return attempts, initialization_error


def run_fetch_attempts(
    ticker_symbol: str,
    attempts: Iterable[FetchAttempt],
    initial_error: Optional[str] = None,
) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
    last_error = initial_error

    for attempt in attempts:
        try:
            raw_data = attempt.loader()
        except (ValueError, JSONDecodeError) as err:
            last_error = f"{attempt.label} è§£æå¤±æ•—: {err}"
            continue
        except Exception as err:
            last_error = f"{attempt.label} ç™¼ç”Ÿä¾‹å¤–: {err}"
            continue

        if raw_data is None or (hasattr(raw_data, "empty") and raw_data.empty):
            last_error = f"{attempt.label} å›å‚³ç©ºè³‡æ–™"
            continue

        try:
            normalized = _normalize_history_df(raw_data, ticker_symbol)
        except Exception as err:
            last_error = f"{attempt.label} æ­£è¦åŒ–è³‡æ–™å¤±æ•—: {err}"
            continue

        return normalized, None

    return None, last_error or "æœªçŸ¥åŸå› "


def fetch_stock_data(ticker_symbol: str, years: int = 5) -> Optional[pd.DataFrame]:
    ticker_symbol = ticker_symbol.upper()
    years = max(1, min(years, 20))

    try:
        print(f"æ­£åœ¨æŠ“å–è‚¡ç¥¨ {ticker_symbol} çš„ {years} å¹´æ­·å²è³‡æ–™...")
    except Exception:
        print(f"Fetching {ticker_symbol} data for {years} years...")

    session = get_yf_session()
    warm_up_session(session, ticker_symbol)

    attempts, initialization_error = build_fetch_attempts(ticker_symbol, years, session)
    data, error_message = run_fetch_attempts(ticker_symbol, attempts, initialization_error)

    if data is not None:
        try:
            print(f"æˆåŠŸæŠ“å– {len(data)} æ¢æ•¸æ“š (å¾ {data['Date'].min()} åˆ° {data['Date'].max()})")
        except Exception:
            print(f"Successfully fetched {len(data)} records")
        return data

    reason = error_message or "æœªçŸ¥åŸå› "
    try:
        print(f"æŠ“å–è‚¡ç¥¨ {ticker_symbol} è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {reason}")
    except Exception:
        print(f"Error fetching {ticker_symbol}: {reason}")
    return None


def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="æŠ“å–è‚¡ç¥¨æ­·å²è³‡æ–™")
    parser.add_argument("-t", "--ticker", type=str, help="è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: AAPL, 2330.TW, ETH-USD)")
    parser.add_argument("-y", "--years", type=int, default=5, help="è¦æŠ“å–çš„å¹´æ•¸ (é è¨­: 5)")
    parser.add_argument(
        "-o",
        "--output",
        type=str,
        default="data/data.csv",
        help="è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ (é è¨­: data/data.csv)",
    )
    parser.add_argument("--interactive", action="store_true", help="ä½¿ç”¨äº’å‹•æ¨¡å¼è¼¸å…¥åƒæ•¸")
    return parser


def get_user_input() -> Tuple[str, int]:
    print("=" * 50)
    print("ğŸ“ˆ è‚¡ç¥¨è³‡æ–™æŠ“å–å·¥å…·")
    print("=" * 50)

    while True:
        ticker = input("è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: AAPL, 2330.TW, ETH-USD): ").strip().upper()
        if ticker:
            break
        print("è‚¡ç¥¨ä»£è™Ÿä¸èƒ½ç‚ºç©ºï¼Œè«‹é‡æ–°è¼¸å…¥")

    while True:
        years_input = input("è«‹è¼¸å…¥è¦æŠ“å–çš„å¹´æ•¸ (é è¨­5å¹´ï¼Œç›´æ¥æŒ‰Enterä½¿ç”¨é è¨­å€¼): ").strip()
        if not years_input:
            return ticker, 5
        try:
            years = int(years_input)
        except ValueError:
            print("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ•¸å­—")
            continue
        if 0 < years <= 20:
            return ticker, years
        print("å¹´æ•¸å¿…é ˆåœ¨1-20ä¹‹é–“")


def main(argv: Optional[Iterable[str]] = None) -> int:
    parser = build_parser()
    args = parser.parse_args(list(argv) if argv is not None else None)

    if args.interactive or (not args.ticker):
        ticker, years = get_user_input()
        filename = args.output
    else:
        ticker = args.ticker.upper()
        years = args.years
        filename = args.output

    os.makedirs(os.path.dirname(filename), exist_ok=True)

    data = fetch_stock_data(ticker, years=years)

    if data is not None:
        data.to_csv(filename, index=False)
        print(f"âœ… è‚¡ç¥¨ {ticker} çš„ {years} å¹´åŸå§‹è³‡æ–™å·²æˆåŠŸæŠ“å–ï¼Œä¸¦ä¿å­˜åˆ° {filename}")
        print(f"ğŸ“Š æ•¸æ“šæ¦‚è¦½: {len(data)} æ¢è¨˜éŒ„ï¼Œæ—¥æœŸç¯„åœ: {data['Date'].min()} - {data['Date'].max()}")
        return 0

    print(f"âŒ ç„¡æ³•ç²å–è‚¡ç¥¨ {ticker} çš„è³‡æ–™ï¼Œè«‹æª¢æŸ¥è‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢º")
    return 1


__all__ = [
    "FetchAttempt",
    "fetch_stock_data",
    "build_fetch_attempts",
    "run_fetch_attempts",
    "get_yf_session",
    "warm_up_session",
    "main",
]
